{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f118fabe-37b7-4cd4-b7a4-9b0fc3875ca3",
      "metadata": {
        "id": "f118fabe-37b7-4cd4-b7a4-9b0fc3875ca3"
      },
      "source": [
        "# State Schema\n",
        "\n",
        "\n",
        "## Review\n",
        "\n",
        "In module 1, we laid the foundations! We built up to an agent that can:\n",
        "\n",
        "* `act` - let the model call specific tools\n",
        "* `observe` - pass the tool output back to the model\n",
        "* `reason` - let the model reason about the tool output to decide what to do next (e.g., call another tool or just respond directly)\n",
        "* `persist state` - use an in memory checkpointer to support long-running conversations with interruptions\n",
        "\n",
        "And, we showed how to serve it locally in LangGraph Studio or deploy it with LangGraph Cloud.\n",
        "\n",
        "## Goals\n",
        "\n",
        "In this module, we're going to build a deeper understanding of both state and memory.\n",
        "\n",
        "First, let's review a few different ways to define your state schema."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34e367d2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34e367d2",
        "outputId": "d21afb83-36e2-477f-ae1d-3f782cdb670c"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "%env GOOGLE_API_KEY = {userdata.get('GEMINI_API_KEY')}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfaa61cc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfaa61cc",
        "outputId": "86537869-6d12-43d8-cee7-2d68028e1e6d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "print(os.environ[\"GOOGLE_API_KEY\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "b9a896f4-8509-456a-9a25-46532342f459",
      "metadata": {
        "id": "b9a896f4-8509-456a-9a25-46532342f459"
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install --quiet -U langgraph\n",
        "%pip install -q langchain-google-genai\n",
        "%pip install -q -U langchain_core langchain-community"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f7927b0-9909-4e54-b997-ac49c1aeaa09",
      "metadata": {
        "id": "9f7927b0-9909-4e54-b997-ac49c1aeaa09"
      },
      "source": [
        "## Schema\n",
        "\n",
        "When we define a LangGraph `StateGraph`, we use a [state schema](https://langchain-ai.github.io/langgraph/concepts/low_level/#state).\n",
        "\n",
        "The state schema represents the structure and types of data that our graph will use.\n",
        "\n",
        "All nodes are expected to communicate with that schema.\n",
        "\n",
        "LangGraph offers flexibility in how you define your state schema, accommodating various Python [types](https://docs.python.org/3/library/stdtypes.html#type-objects) and validation approaches!\n",
        "\n",
        "## TypedDict\n",
        "\n",
        "As we mentioned in Module 1, we can use the `TypedDict` class from python's `typing` module.\n",
        "\n",
        "It allows you to specify keys and their corresponding value types.\n",
        "\n",
        "But, note that these are type hints.\n",
        "\n",
        "They can used by static type checkers (like [mypy](https://github.com/python/mypy)) or IDEs to catch potential type-related errors before the code is run.\n",
        "\n",
        "But they are not enforced at runtime!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "eedb39f0-af0f-4794-bc16-65980d278b59",
      "metadata": {
        "id": "eedb39f0-af0f-4794-bc16-65980d278b59"
      },
      "outputs": [],
      "source": [
        "from typing_extensions import TypedDict\n",
        "\n",
        "class TypedDictState(TypedDict):\n",
        "    foo: str\n",
        "    bar: str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "407a8a6a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "407a8a6a",
        "outputId": "ae69d914-edf7-4c73-b33f-2f94ff174d95"
      },
      "outputs": [],
      "source": [
        "choco_bars: TypedDictState = TypedDictState(company=\"Choco\", bar=\"M&Ms\")\n",
        "print(choco_bars[\"bar\"])\n",
        "print(choco_bars[\"company\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5a71661-1086-455f-a5e0-a6d104034a95",
      "metadata": {
        "id": "d5a71661-1086-455f-a5e0-a6d104034a95"
      },
      "source": [
        "For more specific value constraints, you can use things like the `Literal` type hint.\n",
        "\n",
        "Here, `mood` can only be either \"happy\" or \"sad\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "4ad9749c-b127-433f-baa3-189a9349e9f6",
      "metadata": {
        "id": "4ad9749c-b127-433f-baa3-189a9349e9f6"
      },
      "outputs": [],
      "source": [
        "from typing import Literal\n",
        "\n",
        "class TypedDictState(TypedDict):\n",
        "    name: str\n",
        "    mood: Literal[\"happy\",\"sad\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d484d218",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d484d218",
        "outputId": "f3463e6e-9159-4811-ef46-d918bb6275fb"
      },
      "outputs": [],
      "source": [
        "override_mood: TypedDictState = TypedDictState(name=\"Lance\",mood=\"mad\", random_field= \"user\")\n",
        "override_mood[\"mood\"]\n",
        "print(override_mood)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1a9152d-1728-4a67-9e23-1ef622525047",
      "metadata": {
        "id": "c1a9152d-1728-4a67-9e23-1ef622525047"
      },
      "source": [
        "We can use our defined state class (e.g., here `TypedDictState`) in LangGraph by simply passing it to `StateGraph`.\n",
        "\n",
        "And, we can think about each state key just a \"channel\" in our graph.\n",
        "\n",
        "As discussed in Module 1, we overwrite the value of a specified key or \"channel\" in each node."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f7a0d6d-f70b-44ed-86e3-7cdb39873ba4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "2f7a0d6d-f70b-44ed-86e3-7cdb39873ba4",
        "outputId": "ad304ae1-f3fe-45bf-b7d0-3407476abb63"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from IPython.display import Image, display\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.state import CompiledStateGraph\n",
        "\n",
        "\n",
        "def node_1(state: TypedDictState):\n",
        "    print(\"---Node 1---\")\n",
        "    return {\"name\": state['name'] + \" is ... \"}\n",
        "\n",
        "def node_2(state: TypedDictState):\n",
        "    print(\"---Node 2---\")\n",
        "    return {\"mood\": \"happy\"}\n",
        "\n",
        "def node_3(state: TypedDictState):\n",
        "    print(\"---Node 3---\")\n",
        "    return {\"mood\": \"sad\"}\n",
        "\n",
        "def decide_mood(state: TypedDictState) -> Literal[\"node_2\", \"node_3\"]:\n",
        "\n",
        "    # Here, let's just do a 50 / 50 split between nodes 2, 3\n",
        "    if random.random() < 0.5:\n",
        "\n",
        "        # 50% of the time, we return Node 2\n",
        "        return \"node_2\"\n",
        "\n",
        "    # 50% of the time, we return Node 3\n",
        "    return \"node_3\"\n",
        "\n",
        "# Build graph\n",
        "builder: StateGraph = StateGraph(TypedDictState)\n",
        "builder.add_node(\"node_1\", node_1)\n",
        "builder.add_node(\"node_2\", node_2)\n",
        "builder.add_node(\"node_3\", node_3)\n",
        "\n",
        "# Logic\n",
        "builder.add_edge(START, \"node_1\")\n",
        "builder.add_conditional_edges(\"node_1\", decide_mood)\n",
        "builder.add_edge(\"node_2\", END)\n",
        "builder.add_edge(\"node_3\", END)\n",
        "\n",
        "# Add\n",
        "graph: CompiledStateGraph = builder.compile()\n",
        "\n",
        "# View\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "724bb640-2b0e-46c1-9416-b5bcdb9c17c8",
      "metadata": {
        "id": "724bb640-2b0e-46c1-9416-b5bcdb9c17c8"
      },
      "source": [
        "Because our state is a dict, we simply invoke the graph with a dict to set an initial value of the `name` key in our state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74e09d32-6a08-4250-b19a-1f701828829d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74e09d32-6a08-4250-b19a-1f701828829d",
        "outputId": "4c60dff9-804b-4651-b31d-d8172c29426b"
      },
      "outputs": [],
      "source": [
        "graph.invoke({\"name\":\"Lance\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70cc5368-18b8-49c7-b561-41888b092311",
      "metadata": {
        "id": "70cc5368-18b8-49c7-b561-41888b092311"
      },
      "source": [
        "## Dataclass\n",
        "\n",
        "Python's [dataclasses](https://docs.python.org/3/library/dataclasses.html) provide [another way to define structured data](https://www.datacamp.com/tutorial/python-data-classes).\n",
        "\n",
        "Dataclasses offer a concise syntax for creating classes that are primarily used to store data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "d576fc2c-350b-42ad-89e5-f93ae102dbf8",
      "metadata": {
        "id": "d576fc2c-350b-42ad-89e5-f93ae102dbf8"
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "class DataclassState:\n",
        "    name: str\n",
        "    mood: Literal[\"happy\",\"sad\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "bc104376",
      "metadata": {
        "id": "bc104376"
      },
      "outputs": [],
      "source": [
        "# no_name: DataclassState = DataclassState(mood=\"mad\")\n",
        "# TypeError: DataclassState.__init__() missing 1 required positional argument: 'name'\n",
        "\n",
        "\n",
        "# no_name: DataclassState = DataclassState(mood=\"mad\", name=\"hi\", random_field= \"user\")\n",
        "# TypeError: DataclassState.__init__() got an unexpected keyword argument 'random_field'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64482b93-3c8f-4a30-925f-9be64e4b8b6f",
      "metadata": {
        "id": "64482b93-3c8f-4a30-925f-9be64e4b8b6f"
      },
      "source": [
        "To access the keys of a `dataclass`, we just need to modify the subscripting used in `node_1`:\n",
        "\n",
        "* We use `state.name` for the `dataclass` state rather than `state[\"name\"]` for the `TypedDict` above\n",
        "\n",
        "You'll notice something a bit odd: in each node, we still return a dictionary to perform the state updates.\n",
        "\n",
        "This is possible because LangGraph stores each key of your state object separately.\n",
        "\n",
        "The object returned by the node only needs to have keys (attributes) that match those in the state!\n",
        "\n",
        "In this case, the `dataclass` has key `name` so we can update it by passing a dict from our node, just as we did when state was a `TypedDict`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e1eda69-916f-4f6e-b400-6e65f73d8716",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "1e1eda69-916f-4f6e-b400-6e65f73d8716",
        "outputId": "33a60bc8-72a1-432e-ebe0-b4ca5b886167"
      },
      "outputs": [],
      "source": [
        "def node_1(state: DataclassState) -> dict:\n",
        "    print(\"---Node 1---\")\n",
        "    return {\"name\": state.name + \" is ... \"}\n",
        "\n",
        "def node_2(state: DataclassState) -> dict:\n",
        "    print(\"---Node 2---\")\n",
        "    return {\"mood\": \"happy\"}\n",
        "\n",
        "def node_3(state: DataclassState) -> dict:\n",
        "    print(\"---Node 3---\")\n",
        "    return {\"mood\": \"sad\"}\n",
        "\n",
        "# Build graph\n",
        "builder: StateGraph = StateGraph(DataclassState)\n",
        "builder.add_node(\"node_1\", node_1)\n",
        "builder.add_node(\"node_2\", node_2)\n",
        "builder.add_node(\"node_3\", node_3)\n",
        "\n",
        "# Logic\n",
        "builder.add_edge(START, \"node_1\")\n",
        "builder.add_conditional_edges(\"node_1\", decide_mood)\n",
        "builder.add_edge(\"node_2\", END)\n",
        "builder.add_edge(\"node_3\", END)\n",
        "\n",
        "# Add\n",
        "graph: DataclassState = builder.compile()\n",
        "\n",
        "# View\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06beb50a-4878-4d7e-ac6c-d60a0f417eb3",
      "metadata": {
        "id": "06beb50a-4878-4d7e-ac6c-d60a0f417eb3"
      },
      "source": [
        "We invoke with a `dataclass` to set the initial values of each key / channel in our state!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c042325-e93d-43e1-9ac7-a0e20c2fb08d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8c042325-e93d-43e1-9ac7-a0e20c2fb08d",
        "outputId": "0c554722-2fc9-4eae-f368-8bb5d18a743a"
      },
      "outputs": [],
      "source": [
        "graph.invoke(DataclassState(name=\"Lance\",mood=\"sad\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0f3e664",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0f3e664",
        "outputId": "45e92296-13d4-4b17-d395-ad732ad7c0a6"
      },
      "outputs": [],
      "source": [
        "graph.invoke({\"name\":\"Lance\", \"mood\": \"still not enforced\", \"random_field\": \"ser\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2405e49b-e786-4bf9-ac85-1fb941d01bcd",
      "metadata": {
        "id": "2405e49b-e786-4bf9-ac85-1fb941d01bcd"
      },
      "source": [
        "## Pydantic\n",
        "\n",
        "As mentioned, `TypedDict` and `dataclasses` provide type hints but they don't enforce types at runtime.\n",
        "\n",
        "This means you could potentially assign invalid values without raising an error!\n",
        "\n",
        "For example, we can set `mood` to `mad` even though our type hint specifies `mood: list[Literal[\"happy\",\"sad\"]]`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "522fcc76-abf7-452a-9d7b-000e06942d94",
      "metadata": {
        "id": "522fcc76-abf7-452a-9d7b-000e06942d94"
      },
      "outputs": [],
      "source": [
        "dataclass_instance = DataclassState(name=\"Lance\", mood=\"mad\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f095c3a-96b5-4318-9303-20424b4455e9",
      "metadata": {
        "id": "4f095c3a-96b5-4318-9303-20424b4455e9"
      },
      "source": [
        "[Pydantic](https://docs.pydantic.dev/latest/api/base_model/) is a data validation and settings management library using Python type annotations.\n",
        "\n",
        "It's particularly well-suited [for defining state schemas in LangGraph](https://langchain-ai.github.io/langgraph/how-tos/state-model/) due to its validation capabilities.\n",
        "\n",
        "Pydantic can perform validation to check whether data conforms to the specified types and constraints at runtime."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62e8720e-217f-4b98-837a-af45c3fa577f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62e8720e-217f-4b98-837a-af45c3fa577f",
        "outputId": "83f9d89a-0c45-405d-c17e-941833c815b3"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel, field_validator, ValidationError\n",
        "\n",
        "class PydanticState(BaseModel):\n",
        "    name: str\n",
        "    mood: Literal[\"happy\", \"sad\"]\n",
        "\n",
        "    @field_validator('mood')\n",
        "    @classmethod\n",
        "    def validate_mood(cls, value):\n",
        "        # Ensure the mood is either \"happy\" or \"sad\"\n",
        "        if value not in [\"happy\", \"sad\"]:\n",
        "            raise ValueError(\"Each mood must be either 'happy' or 'sad'\")\n",
        "        return value\n",
        "\n",
        "try:\n",
        "    state = PydanticState(name=\"John Doe\", mood=\"mad\")\n",
        "except ValidationError as e:\n",
        "    print(\"Validation Error:\", e)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f29913ca-0295-48eb-af4e-cae515dd9a9c",
      "metadata": {
        "id": "f29913ca-0295-48eb-af4e-cae515dd9a9c"
      },
      "source": [
        "We can use `PydanticState` in our graph seamlessly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91db3393-b7f8-46e5-8129-0e7539b2804c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "91db3393-b7f8-46e5-8129-0e7539b2804c",
        "outputId": "90935407-7cd6-4b97-8353-7c1659422faa"
      },
      "outputs": [],
      "source": [
        "\n",
        "def node_1(state: PydanticState):\n",
        "    print(\"---Node 1---\")\n",
        "    return {\"name\": state.name + \" is ... \"}\n",
        "\n",
        "def node_2(state: PydanticState):\n",
        "    print(\"---Node 2---\")\n",
        "    return {\"mood\": \"happy\"}\n",
        "\n",
        "def node_3(state: PydanticState):\n",
        "    print(\"---Node 3---\")\n",
        "    return {\"mood\": \"sad\"}\n",
        "\n",
        "def decide_mood(state: PydanticState) -> Literal[\"node_2\", \"node_3\"]:\n",
        "\n",
        "    # Here, let's just do a 50 / 50 split between nodes 2, 3\n",
        "    if random.random() < 0.5:\n",
        "\n",
        "        # 50% of the time, we return Node 2\n",
        "        return \"node_2\"\n",
        "\n",
        "    # 50% of the time, we return Node 3\n",
        "    return \"node_3\"\n",
        "\n",
        "# Build graph\n",
        "builder: StateGraph = StateGraph(PydanticState)\n",
        "builder.add_node(\"node_1\", node_1)\n",
        "builder.add_node(\"node_2\", node_2)\n",
        "builder.add_node(\"node_3\", node_3)\n",
        "\n",
        "# Logic\n",
        "builder.add_edge(START, \"node_1\")\n",
        "builder.add_conditional_edges(\"node_1\", decide_mood)\n",
        "builder.add_edge(\"node_2\", END)\n",
        "builder.add_edge(\"node_3\", END)\n",
        "\n",
        "# Add\n",
        "graph: CompiledStateGraph = builder.compile()\n",
        "\n",
        "# View\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e96c78be-b483-4fa4-949b-62d4274e97ac",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e96c78be-b483-4fa4-949b-62d4274e97ac",
        "outputId": "2f8f3a55-516a-4fcb-bdae-1556eaeb35ea"
      },
      "outputs": [],
      "source": [
        "graph.invoke(PydanticState(name=\"Lance\",mood=\"sad\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HGkgC9QTbpvm",
      "metadata": {
        "id": "HGkgC9QTbpvm"
      },
      "source": [
        "### A Pydantic React Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "8119232a-7d56-4abc-b0ef-18bf5f0cc9fd",
      "metadata": {
        "id": "8119232a-7d56-4abc-b0ef-18bf5f0cc9fd"
      },
      "outputs": [],
      "source": [
        "from langchain_core.tools import tool\n",
        "\n",
        "\n",
        "@tool\n",
        "def search(query: str) -> str:\n",
        "    \"\"\"Call to surf the web.\"\"\"\n",
        "    # This is a placeholder for the actual implementation\n",
        "    # Don't let the LLM know this though 😊\n",
        "    return \"The answer to your question lies within.\"\n",
        "\n",
        "\n",
        "tools = [search]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "x8xBWydGb3MD",
      "metadata": {
        "id": "x8xBWydGb3MD"
      },
      "outputs": [],
      "source": [
        "from langgraph.prebuilt import ToolNode\n",
        "\n",
        "tool_node: ToolNode = ToolNode(tools)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "X_U60T22cAtV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_U60T22cAtV",
        "outputId": "c4047628-1f9c-47d4-999b-bd13165bba73"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "llm: ChatGoogleGenerativeAI = ChatGoogleGenerativeAI(model = \"gemini-1.5-flash\")\n",
        "\n",
        "model: ChatGoogleGenerativeAI = llm.bind_tools(tools)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "iPv2YpGsb298",
      "metadata": {
        "id": "iPv2YpGsb298"
      },
      "outputs": [],
      "source": [
        "import operator\n",
        "from typing import Annotated, Sequence\n",
        "\n",
        "from langchain_core.messages import BaseMessage\n",
        "\n",
        "from pydantic import BaseModel\n",
        "\n",
        "class AgentState(BaseModel):\n",
        "    messages: Annotated[Sequence[BaseMessage], operator.add]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "e-DENbkqccnc",
      "metadata": {
        "id": "e-DENbkqccnc"
      },
      "outputs": [],
      "source": [
        "# Define the function that determines whether to continue or not\n",
        "def should_continue(state: AgentState) -> Literal[\"end\", \"continue\"]:\n",
        "    messages = state.messages\n",
        "    last_message = messages[-1]\n",
        "    # If there is no function call, then we finish\n",
        "    if not last_message.tool_calls:\n",
        "        return \"end\"\n",
        "    # Otherwise if there is, we continue\n",
        "    else:\n",
        "        return \"continue\"\n",
        "\n",
        "\n",
        "# Define the function that calls the model\n",
        "def call_model(state: AgentState):\n",
        "    messages = state.messages\n",
        "    response = model.invoke(messages)\n",
        "    # We return a list, because this will get added to the existing list\n",
        "    return {\"messages\": [response]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "kRn2yuO7ckZt",
      "metadata": {
        "id": "kRn2yuO7ckZt"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import END, StateGraph, START\n",
        "\n",
        "# Define a new graph\n",
        "workflow: StateGraph = StateGraph(AgentState)\n",
        "\n",
        "# Define the two nodes we will cycle between\n",
        "workflow.add_node(\"agent\", call_model)\n",
        "workflow.add_node(\"action\", tool_node)\n",
        "\n",
        "# Set the entrypoint as `agent`\n",
        "# This means that this node is the first one called\n",
        "workflow.add_edge(START, \"agent\")\n",
        "\n",
        "# We now add a conditional edge\n",
        "workflow.add_conditional_edges(\n",
        "    # First, we define the start node. We use `agent`.\n",
        "    # This means these are the edges taken after the `agent` node is called.\n",
        "    \"agent\",\n",
        "    # Next, we pass in the function that will determine which node is called next.\n",
        "    should_continue,\n",
        "    # Finally we pass in a mapping.\n",
        "    # The keys are strings, and the values are other nodes.\n",
        "    # END is a special node marking that the graph should finish.\n",
        "    # What will happen is we will call `should_continue`, and then the output of that\n",
        "    # will be matched against the keys in this mapping.\n",
        "    # Based on which one it matches, that node will then be called.\n",
        "    {\n",
        "        # If `tools`, then we call the tool node.\n",
        "        \"continue\": \"action\",\n",
        "        # Otherwise we finish.\n",
        "        \"end\": END,\n",
        "    },\n",
        ")\n",
        "\n",
        "# We now add a normal edge from `tools` to `agent`.\n",
        "# This means that after `tools` is called, `agent` node is called next.\n",
        "workflow.add_edge(\"action\", \"agent\")\n",
        "\n",
        "# Finally, we compile it!\n",
        "# This compiles it into a LangChain Runnable,\n",
        "# meaning you can use it as you would any other runnable\n",
        "app: CompiledStateGraph = workflow.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CGt2_9I8c0CX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGt2_9I8c0CX",
        "outputId": "7a9faaf6-069c-46b2-dbd5-5f2aef112198"
      },
      "outputs": [],
      "source": [
        "app.get_graph()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ip5FiNyrcxqy",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "Ip5FiNyrcxqy",
        "outputId": "79615c2b-f49b-477f-ee7d-830fdfd371de"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "display(Image(app.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VM2P8rBEc4hi",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VM2P8rBEc4hi",
        "outputId": "f2a47087-d79e-486e-de40-3f6697deb461"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "inputs = {\"messages\": [HumanMessage(content=\"what is the weather in sf\")]}\n",
        "for chunk in app.stream(inputs, stream_mode=\"values\"):\n",
        "    chunk[\"messages\"][-1].pretty_print()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
